name: test_uv
permissions:
  contents: read

on:
  push:
    branches: [ main ]
    paths:
      - 'src/**'
      - 'pyproject.toml'
    tags:
      - 'v*.*.*'  # Trigger on release tags like v0.2.5, v1.0.0, etc.
  pull_request:
    branches: [ main ]
    paths-ignore: '**.md'

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

jobs:
  download-models:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-24.04, macos-latest, windows-latest]
    steps:
      - name: Cache model files
        uses: actions/cache@v4
        id: cache-models
        with:
          path: |
            ~/.cache/huggingface/hub
            ~/.cache/modelscope/hub
          key: models-v2-${{ runner.os }}

      - name: Set up Python
        if: steps.cache-models.outputs.cache-hit != 'true'
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Download models
        if: steps.cache-models.outputs.cache-hit != 'true'
        run: |
          pip install modelscope huggingface_hub
          # ModelScope: alignment models
          python -c "from modelscope.hub.snapshot_download import snapshot_download; snapshot_download('LattifAI/Lattice-1-Alpha')"
          python -c "from modelscope.hub.snapshot_download import snapshot_download; snapshot_download('LattifAI/Lattice-1')"
          # ModelScope: transcription model
          python -c "from modelscope.hub.snapshot_download import snapshot_download; snapshot_download('iic/SenseVoiceSmall')"
          # ModelScope: sentence splitter (wtpsplit/SaT) for split_sentence=true
          python -c "from modelscope.hub.snapshot_download import snapshot_download; snapshot_download('LattifAI/OmniTokenizer')"

  test:
    needs: [download-models]
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-24.04, macos-latest, windows-latest]
        python-version: ['3.10', '3.13']  # , '3.14'

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Install Dependencies
        run: |
          uv sync --prerelease=allow --all-extras

      - name: Restore model cache
        uses: actions/cache/restore@v4
        with:
          path: |
            ~/.cache/huggingface/hub
            ~/.cache/modelscope/hub
          key: models-v2-${{ runner.os }}

      - name: Build and Test
        if: runner.os != 'Windows'
        env:
          LATTIFAI_API_KEY: ${{ secrets.LATTIFAI_API_KEY }}
        run: |
          uv run python tests/test_basic.py  # Run basic tests

      - name: Test Cli Commands (Unix & Windows)
        env:
          LATTIFAI_API_KEY: ${{ secrets.LATTIFAI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          # Test lai-transcribe command
          uv run which lai
          # alignment align
          uv run bash tests/test_audio_formats.sh  # Run audio format tests
          # Gemini Model
          # uv run lai-transcribe -Y tests/data/SA1.wav transcription.model_name=gemini-3-pro-preview -v
          # uv run lai transcribe align -Y -v tests/data/SA1.wav transcription.model_name=gemini-3-flash-preview

      # - name: Test Cli Commands (Windows)
      #   if: runner.os == 'Windows'
      #   env:
      #     LATTIFAI_API_KEY: ${{ secrets.LATTIFAI_API_KEY }}
      #     GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      #   run: |
